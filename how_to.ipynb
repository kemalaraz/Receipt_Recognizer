{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc18fa25",
   "metadata": {},
   "source": [
    "## High level usage of Receipt Recognizer\n",
    "\n",
    "I approached the problem by first detecting the text by a detector called craft, then recognized the letters by two models google's tesseract and a resnet + bilstm + attention model by kind of ensembling them. After that I trained a ner model for detecting the business names, dates and total amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ef7bd",
   "metadata": {},
   "source": [
    "#### Brief explaination\n",
    "I tried to write as modular as possible. I want to change it to factory design pattern where the models classes can be called seperately. The usage of it is fairly easy with few flaws which I am showing below. It starts with loading the pretrained model then it adds on to itself. I wanted to add a ner model on top of everything but because of the time constraints I couldn't however I will train a ner model with a prior repository of mine after resolving its bugs and share that in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451966c",
   "metadata": {},
   "source": [
    "#### Analysis part\n",
    "Since this is image processing there is not much to do however I wrote a analysis part which has filters especially derivative filter which finds the horizontal and vertical edges. By applying max pooling to that it can be clearly seen that the part that has characters and not can be easily seperable. However since I will do ner after the seperable parts can be more than one line most of the time so doing ocr to that parts will give irrational sentence sequences which will effect ner model (I will use pre-trained large bert uncased model) that is why I used a big and a bit heavy detection model. However that model is fairly easy to understand and hasn't got much loops and dynamic parts which means it can be pruned easily. In addition to that it can be quantized and converted to intermediate representations like ONNX which will not only make model faster but also will save from its dependencies so that will make it deployable to any machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660df24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: receiptrecognizer in ./src (0.0.5.1)\n",
      "Requirement already satisfied: numpy in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (1.20.3)\n",
      "Requirement already satisfied: natsort in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (7.1.1)\n",
      "Requirement already satisfied: imutils in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (0.5.4)\n",
      "Requirement already satisfied: shapely in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (1.7.1)\n",
      "Requirement already satisfied: requests in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (2.25.1)\n",
      "Requirement already satisfied: pytesseract in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (0.3.7)\n",
      "Requirement already satisfied: scikit-image in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (0.18.1)\n",
      "Requirement already satisfied: torch==1.5.1 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (1.5.1)\n",
      "Requirement already satisfied: torchvision in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (0.6.1)\n",
      "Requirement already satisfied: opencv-python in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (4.5.2.54)\n",
      "Requirement already satisfied: googledrivedownloader==0.4 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from receiptrecognizer) (0.4)\n",
      "Requirement already satisfied: future in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from torch==1.5.1->receiptrecognizer) (0.18.2)\n",
      "Requirement already satisfied: Pillow in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from pytesseract->receiptrecognizer) (8.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from requests->receiptrecognizer) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from requests->receiptrecognizer) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from requests->receiptrecognizer) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from requests->receiptrecognizer) (1.26.5)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from scikit-image->receiptrecognizer) (3.4.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from scikit-image->receiptrecognizer) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from scikit-image->receiptrecognizer) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from scikit-image->receiptrecognizer) (2021.6.14)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from scikit-image->receiptrecognizer) (2.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from scikit-image->receiptrecognizer) (1.6.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->receiptrecognizer) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->receiptrecognizer) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->receiptrecognizer) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->receiptrecognizer) (2.8.1)\n",
      "Requirement already satisfied: six in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->receiptrecognizer) (1.16.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/kemalaraz/anaconda3/envs/receipt/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->receiptrecognizer) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install receiptrecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2dbeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from receiptrecognizer import ReceiptRecognizer as rr\n",
    "from receiptrecognizer.utils import ImageUtils\n",
    "from receiptrecognizer.models import Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faed6686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:receiptrecognizer.model_downloader:Downloding model to /home/kemalaraz/receipt_models from google drive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ into /home/kemalaraz/receipt_models/craft_mlt_25k.pth... \n",
      "79.3 MiB          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:receiptrecognizer.module:Model downloaded to /home/kemalaraz/receipt_models/craft_mlt_25k.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Craft(\n",
       "  (backbone): VGG16(\n",
       "    (slice1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (slice2): Sequential(\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (slice3): Sequential(\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (slice4): Sequential(\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (36): ReLU(inplace=True)\n",
       "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (slice5): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "      (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (upconv1): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv2): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv3): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv4): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_cls): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the class with first model which is detection\n",
    "model = rr.from_pretrained(\"craft_mlt_25k.pth\")\n",
    "# convert detector to eval mode\n",
    "model.detector.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8945672",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"src/test_instances/raw_images\" # path of the test image\n",
    "results_path = \"src/test_instances/results_detection\" # path of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c862ce21",
   "metadata": {},
   "source": [
    "### One image example - if more than one put into folder this will also work\n",
    "THE GOOGLE DRIVE DOWNLOAD LINK IS BROKEN FOR RECOGNITION MODEL SO AUTO DOWNLOAD WONT WORK PLEASE DOWNLOAD IT FROM \n",
    "https://drive.google.com/file/d/1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9/view AND PUT UNDER /home/user/receipt_models FOR UBUNTU AND C:\\USERS\\username\\receipt_models FOR WINDOWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f11a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for k, image_path in enumerate(os.listdir(test_path)): # TODO: Can be changed with imutils paths.listimages(path)\n",
    "    image_path = os.path.join(test_path, image_path)\n",
    "    image = ImageUtils.loadImage(image_path)\n",
    "\n",
    "    # Get the outcome of the detection model\n",
    "    bboxes, polys, heatmap = model.detection(image)\n",
    "\n",
    "    # crop images according to bboxes\n",
    "    cropped_images = ImageUtils.crop_image(image[:,:,::-1], bboxes)\n",
    "\n",
    "    image_results_path = os.path.join(results_path, os.path.basename(image_path).split(\"-\")[0])\n",
    "    if not os.path.exists(image_results_path):\n",
    "        os.makedirs(image_results_path, exist_ok = True)\n",
    "\n",
    "    # Get tesseract results and write cropped images to a folder\n",
    "    tesseract_results = []\n",
    "    for e, cropped_image in enumerate(cropped_images):\n",
    "        cv2.imwrite(os.path.join(image_results_path, f\"{e}-det-\"+ os.path.basename(image_path)), cropped_image)\n",
    "        tesseract_results.append(Tesseract.predict(cropped_image))\n",
    "\n",
    "    # Find the characters from the folders that cropped images were written\n",
    "    # Do recognition with recognition model\n",
    "    craft_rec_results = model.recognition(image_folder = image_results_path)\n",
    "    filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
    "    mask_file = results_path + \"/res_\" + filename + '_mask.jpg'\n",
    "    cv2.imwrite(mask_file, heatmap)\n",
    "\n",
    "    #FileHandler.saveResult(image_path, image[:,:,::-1], bboxes)\n",
    "    \n",
    "    # Ensemble the tesseract's and recognition model's results and regex them a bit to get final results\n",
    "    alligned_results = model.allign_char_results(tesseract_results, craft_rec_results)\n",
    "    all_results.append(alligned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe06cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Dona Mercedes Restaurant', '1030 1/2 San Fernando Rd', 'San Fernando CA 91341', 'Vero', 'CENTERL', '1 CHicharon', '8225', '3 Pupusa Queso', '$6.75', '1 Platanos Orden', '8775', '1 Diet coke', '$1.50', '2 Quesadilla salvadorena', '$4.00', 'SUBTOTAL: $22.25', 'TAX: $2.22', 'TOTAL: $24.47', 'TIP SUGGESTIONS', '18714440', '20%: $4.89', '25%: $6.12', 'Thank You!']]\n"
     ]
    }
   ],
   "source": [
    "print(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55957587",
   "metadata": {},
   "source": [
    "#### Explainable AI\n",
    "I saved the attentions that the craft model is attending at the time of inference for understanding where the model is concentrating when creating the bounding boxes, given time I can extend it to all the layers and add it to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908db908",
   "metadata": {},
   "source": [
    "### NER\n",
    "I was planning to train a ner model in order to find the named entities requested however due to the time constraints I was unable to do that. I even labelled the dataset which is also shared and was editing my named entity recognition repository which is https://github.com/kemalaraz/NamedEntityRecognizer. But it has some flaws when it comes to CoNNL format which I labelled my dataset according to that is why I am skipping that part."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
